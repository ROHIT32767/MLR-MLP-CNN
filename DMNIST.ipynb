{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "root_directory = './double_mnist'\n",
    "def display_images_from_folder(folder_path, num_images=4):\n",
    "    image_files = os.listdir(folder_path)\n",
    "    random_images = random.sample(image_files, num_images)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, image_file in enumerate(random_images):\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = imread(image_path)\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(f\"Image {i + 1}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "train_folder = os.path.join(root_directory, 'train', '01') \n",
    "display_images_from_folder(train_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '04', '05', '06', '08', '09', '11', '12', '13', '14', '15', '16', '18', '19', '20', '21', '23', '24', '26', '28', '29', '30', '31', '33', '35', '37', '38', '41', '42', '43', '44', '45', '50', '51', '53', '54', '56', '59', '60', '62', '63', '65', '69', '70', '72', '74', '75', '76', '77', '79', '81', '82', '84', '85', '87', '88', '89', '90', '91', '94', '95', '97', '98']\n",
      "Dataset CustomImageFolder\n",
      "    Number of datapoints: 64000\n",
      "    Root location: double_mnist/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_data_path = 'double_mnist/train'\n",
    "val_data_path = 'double_mnist/val'\n",
    "test_data_path = 'double_mnist/test'\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(CustomImageFolder, self).__init__(root, transform=transform)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        folder_name = os.path.basename(os.path.dirname(path))\n",
    "        return sample, int(folder_name) \n",
    "    \n",
    "train_dataset = CustomImageFolder(train_data_path, transform=transform)\n",
    "val_dataset = CustomImageFolder(val_data_path, transform=transform)\n",
    "test_dataset = CustomImageFolder(test_data_path, transform=transform)\n",
    "print(train_dataset.classes)\n",
    "class_to_label = {str(i).zfill(2): i for i in range(100)}\n",
    "# Define batch sizes\n",
    "batch_size = 64\n",
    "print(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "num_classes = 10\n",
    "class_names = train_dataset.classes\n",
    "class_names = val_dataset.classes\n",
    "# print(class_names)\n",
    "# for images, labels in train_loader:\n",
    "#     print(labels)\n",
    "#     break\n",
    "# for images, labels in val_loader:\n",
    "#     plt.imshow(images[0].permute(1, 2, 0))\n",
    "#     print(labels[0])\n",
    "#     print(labels)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP On Double-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiMNIST_MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate=0.5):\n",
    "        super(MultiMNIST_MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_neurons[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        for i in range(1, hidden_layers):\n",
    "            layers.append(nn.Linear(hidden_neurons[i-1], hidden_neurons[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(hidden_neurons[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.hidden(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_left, model_right , train_loader, val_loader, criterion_left, optimizer_left, criterion_right, optimizer_right,num_epochs=5):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_acc, val_acc = [] , []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # left half\n",
    "        model_left.train()\n",
    "        running_loss_left = 0.0\n",
    "        correct_train_left = 0\n",
    "        total_train_left = 0\n",
    "\n",
    "        # right half\n",
    "        model_right.train()\n",
    "        running_loss_right = 0.0\n",
    "        correct_train_right = 0\n",
    "        total_train_right = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # left half\n",
    "            labels_group_left = labels//10\n",
    "            optimizer_left.zero_grad()\n",
    "            image_left = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image_left[:, :, :, (image_left.shape[3] // 2):] = left_half\n",
    "            outputs_left = model_left(image_left)\n",
    "            loss_left = criterion_left(outputs_left, labels_group_left)\n",
    "            loss_left.backward()\n",
    "            optimizer_left.step()\n",
    "            running_loss_left += loss_left.item()\n",
    "            _, predicted_left = torch.max(outputs_left.data, 1)\n",
    "            total_train_left += labels.size(0)\n",
    "            for k in range(labels.size(0)):\n",
    "                if(labels_group_left[k]==predicted_left[k]):\n",
    "                    correct_train_left = correct_train_left+1\n",
    "            # right half\n",
    "            labels_group_right = labels % 10\n",
    "            optimizer_right.zero_grad()\n",
    "            image_right = images.clone()\n",
    "            right_half = images[:, :, :, images.shape[3] // 2:]\n",
    "            image_right[:, :, :, :(image_right.shape[3] // 2)] = right_half\n",
    "            outputs_right = model_right(image_right)\n",
    "            loss_right = criterion_right(outputs_right, labels_group_right)\n",
    "            loss_right.backward()\n",
    "            optimizer_right.step()\n",
    "            running_loss_right += loss_right.item()\n",
    "            _, predicted_right = torch.max(outputs_right.data, 1)\n",
    "            total_train_right += labels.size(0)\n",
    "            for k in range(labels.size(0)):\n",
    "                if(labels_group_right[k]==predicted_right[k]):\n",
    "                    correct_train_right = correct_train_right+1\n",
    "\n",
    "\n",
    "        train_accuracy = 100 * (correct_train_left+correct_train_right) / (total_train_left+total_train_right)\n",
    "        train_losses.append((running_loss_right+running_loss_left) / (2*len(train_loader)))\n",
    "        train_acc.append(train_accuracy)\n",
    "        # left half\n",
    "        model_left.eval()\n",
    "        val_loss_left = 0.0\n",
    "        correct_val_left = 0\n",
    "        total_val_left = 0\n",
    "        count_left = 0\n",
    "        # right half\n",
    "        model_right.eval()\n",
    "        val_loss_right = 0.0\n",
    "        correct_val_right = 0\n",
    "        total_val_right = 0\n",
    "        count_right = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                # left half\n",
    "                labels_group_left = labels // 10\n",
    "                image_left = images.clone()\n",
    "                left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "                image_left[:, :, :, (image_left.shape[3] // 2):] = left_half\n",
    "                outputs_left = model_left(image_left)\n",
    "                loss_left = criterion_left(outputs_left, labels_group_left)\n",
    "                val_loss_left += loss_left.item()\n",
    "                _, predicted_left = torch.max(outputs_left.data, 1)\n",
    "                total_val_left += labels.size(0)\n",
    "                correct_val_left += (predicted_left == labels_group_left).sum().item()\n",
    "                count_left = count_left+1\n",
    "                # right half\n",
    "                labels_group_right = labels % 10\n",
    "                image_right = images.clone()\n",
    "                right_half = images[:, :, :, images.shape[3] // 2:]\n",
    "                image_right[:, :, :, :(image_right.shape[3] // 2)] = right_half\n",
    "                outputs_right = model_right(image_right)\n",
    "                loss_right = criterion_right(outputs_right, labels_group_right)\n",
    "                val_loss_right += loss_right.item()\n",
    "                _, predicted_right = torch.max(outputs_right.data, 1)\n",
    "                total_val_right += labels.size(0)\n",
    "                correct_val_right += (predicted_right == labels_group_right).sum().item()\n",
    "                count_right = count_right+1\n",
    "\n",
    "            val_accuracy = 100 * (correct_val_left+correct_val_right) / (total_val_left+total_val_right)\n",
    "            val_losses.append((val_loss_left+val_loss_right) / (2*len(val_loader)))\n",
    "            val_acc.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    return train_losses, val_losses, train_acc, val_acc\n",
    "\n",
    "\n",
    "def test_model(model_left, model_right , test_loader, criterion_left,criterion_right):\n",
    "    # left half\n",
    "    model_left.eval()\n",
    "    test_loss_left = 0.0\n",
    "    correct_test_left = 0\n",
    "    total_test_left = 0\n",
    "    count_left = 0\n",
    "    # right half\n",
    "    model_right.eval()\n",
    "    test_loss_right = 0.0\n",
    "    correct_test_right = 0\n",
    "    total_test_right = 0\n",
    "    count_right = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # left half\n",
    "            labels_group_left = labels // 10\n",
    "            image_left = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image_left[:, :, :, (image_left.shape[3] // 2):] = left_half\n",
    "            outputs_left = model_left(image_left)\n",
    "            loss_left = criterion_left(outputs_left, labels_group_left)\n",
    "            test_loss_left += loss_left.item()\n",
    "            _, predicted_left = torch.max(outputs_left.data, 1)\n",
    "            total_test_left += labels.size(0)\n",
    "            correct_test_left += (predicted_left == labels_group_left).sum().item()\n",
    "            count_left = count_left+1\n",
    "            # right half\n",
    "            labels_group_right = labels % 10\n",
    "            image_right = images.clone()\n",
    "            right_half = images[:, :, :, images.shape[3] // 2:]\n",
    "            image_right[:, :, :, :(image_right.shape[3] // 2)] = right_half\n",
    "            outputs_right = model_right(image_right)\n",
    "            loss_right = criterion_right(outputs_right, labels_group_right)\n",
    "            test_loss_right += loss_right.item()\n",
    "            _, predicted_right = torch.max(outputs_right.data, 1)\n",
    "            total_test_right += labels.size(0)\n",
    "            correct_test_right += (predicted_right == labels_group_right).sum().item()\n",
    "            count_right = count_right+1\n",
    "        test_accuracy = 100 * (correct_test_left+correct_test_right) / (total_test_left+total_test_right)\n",
    "        average_test_loss = ((test_loss_left+test_loss_right) / (2*len(test_loader)))\n",
    "\n",
    "    print(f'Test Loss: {average_test_loss:.4f}, Test Acc: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.9275, Train Acc: 30.43%, Val Loss: 1.7732, Val Acc: 33.94%\n",
      "Epoch 2/5, Train Loss: 1.5415, Train Acc: 44.86%, Val Loss: 1.3347, Val Acc: 51.00%\n",
      "Epoch 3/5, Train Loss: 1.1840, Train Acc: 58.19%, Val Loss: 0.9840, Val Acc: 65.37%\n",
      "Epoch 4/5, Train Loss: 0.9346, Train Acc: 67.99%, Val Loss: 0.8256, Val Acc: 71.18%\n",
      "Epoch 5/5, Train Loss: 0.7800, Train Acc: 73.84%, Val Loss: 0.6564, Val Acc: 77.78%\n",
      "Test Loss: 0.7110, Test Acc: 76.04%\n"
     ]
    }
   ],
   "source": [
    "model_left = MultiMNIST_MLP(input_size=784,num_classes=num_classes,hidden_layers=3,hidden_neurons=[256,256,256])\n",
    "model_right = MultiMNIST_MLP(input_size=784,num_classes=num_classes,hidden_layers=3,hidden_neurons=[256,256,256])\n",
    "learning_rate = 0.001\n",
    "criterion_left = nn.CrossEntropyLoss()\n",
    "optimizer_left = optim.Adam(model_left.parameters(), lr=learning_rate)\n",
    "criterion_right = nn.CrossEntropyLoss()\n",
    "optimizer_right = optim.Adam(model_right.parameters(), lr=learning_rate)\n",
    "train_losses, val_losses, train_acc, val_acc = train_model(model_left=model_left,model_right=model_right,train_loader=train_loader, val_loader=val_loader, criterion_left=criterion_left, optimizer_left=optimizer_left,criterion_right=criterion_right,optimizer_right=optimizer_right,num_epochs=5)\n",
    "criterion_left = nn.CrossEntropyLoss()\n",
    "optimizer_left = optim.Adam(model_left.parameters(), lr=learning_rate)\n",
    "criterion_right = nn.CrossEntropyLoss()\n",
    "optimizer_right = optim.Adam(model_right.parameters(), lr=learning_rate)\n",
    "test_model(model_left=model_left,model_right=model_right,test_loader=test_loader,criterion_left=criterion_left,criterion_right=criterion_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP on MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 13.4032, Test Acc: 7.63%\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = int(0.1 * len(trainset))\n",
    "test_size = len(trainset) - train_size - val_size\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(trainset, [train_size, val_size, test_size])\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "test_model(model_left=model_left,model_right=model_right,test_loader=test_loader,criterion_left=criterion_left,criterion_right=criterion_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on Double-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '04', '05', '06', '08', '09', '11', '12', '13', '14', '15', '16', '18', '19', '20', '21', '23', '24', '26', '28', '29', '30', '31', '33', '35', '37', '38', '41', '42', '43', '44', '45', '50', '51', '53', '54', '56', '59', '60', '62', '63', '65', '69', '70', '72', '74', '75', '76', '77', '79', '81', '82', '84', '85', '87', '88', '89', '90', '91', '94', '95', '97', '98']\n",
      "Dataset CustomImageFolder\n",
      "    Number of datapoints: 64000\n",
      "    Root location: double_mnist/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Grayscale(num_output_channels=1)\n",
      "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_data_path = 'double_mnist/train'\n",
    "val_data_path = 'double_mnist/val'\n",
    "test_data_path = 'double_mnist/test'\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(CustomImageFolder, self).__init__(root, transform=transform)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        folder_name = os.path.basename(os.path.dirname(path))\n",
    "        return sample, int(folder_name) \n",
    "    \n",
    "train_dataset = CustomImageFolder(train_data_path, transform=transform)\n",
    "val_dataset = CustomImageFolder(val_data_path, transform=transform)\n",
    "test_dataset = CustomImageFolder(test_data_path, transform=transform)\n",
    "print(train_dataset.classes)\n",
    "class_to_label = {str(i).zfill(2): i for i in range(100)}\n",
    "# Define batch sizes\n",
    "batch_size = 64\n",
    "print(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "num_classes = 10\n",
    "class_names = train_dataset.classes\n",
    "class_names = val_dataset.classes\n",
    "# print(class_names)\n",
    "# for images, labels in train_loader:\n",
    "#     print(labels)\n",
    "#     break\n",
    "# for images, labels in val_loader:\n",
    "#     plt.imshow(images[0].permute(1, 2, 0))\n",
    "#     print(labels[0])\n",
    "#     print(labels)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMNIST_CNN(nn.Module):\n",
    "    def __init__(self, input_channels , num_classes , dropout_size=0.25, strides=2, kernel_size=3, pool_size=2):\n",
    "        super(MultiMNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=kernel_size, padding=int((kernel_size-1)/2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=pool_size, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=int((kernel_size-1)/2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=pool_size, stride=strides)\n",
    "        self.var1 = int((28-pool_size)/strides)+1\n",
    "        self.dim = int((self.var1-pool_size)/strides)+1\n",
    "        self.fc1 = nn.Linear(64 * self.dim * self.dim, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_size)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * self.dim * self.dim)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = MultiMNIST_CNN(input_channels=1,num_classes=num_classes)\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_left, model_right , train_loader, val_loader, criterion_left, optimizer_left, criterion_right, optimizer_right,num_epochs=5):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_acc, val_acc = [] , []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # left half\n",
    "        model_left.train()\n",
    "        running_loss_left = 0.0\n",
    "        correct_train_left = 0\n",
    "        total_train_left = 0\n",
    "\n",
    "        # right half\n",
    "        model_right.train()\n",
    "        running_loss_right = 0.0\n",
    "        correct_train_right = 0\n",
    "        total_train_right = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # left half\n",
    "            labels_group_left = labels//10\n",
    "            optimizer_left.zero_grad()\n",
    "            image_left = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image_left[:, :, :, (image_left.shape[3] // 2):] = left_half\n",
    "            outputs_left = model_left(image_left)\n",
    "            loss_left = criterion_left(outputs_left, labels_group_left)\n",
    "            loss_left.backward()\n",
    "            optimizer_left.step()\n",
    "            running_loss_left += loss_left.item()\n",
    "            _, predicted_left = torch.max(outputs_left.data, 1)\n",
    "            total_train_left += labels.size(0)\n",
    "            for k in range(labels.size(0)):\n",
    "                if(labels_group_left[k]==predicted_left[k]):\n",
    "                    correct_train_left = correct_train_left+1\n",
    "            # right half\n",
    "            labels_group_right = labels % 10\n",
    "            optimizer_right.zero_grad()\n",
    "            image_right = images.clone()\n",
    "            right_half = images[:, :, :, images.shape[3] // 2:]\n",
    "            image_right[:, :, :, :(image_right.shape[3] // 2)] = right_half\n",
    "            outputs_right = model_right(image_right)\n",
    "            loss_right = criterion_right(outputs_right, labels_group_right)\n",
    "            loss_right.backward()\n",
    "            optimizer_right.step()\n",
    "            running_loss_right += loss_right.item()\n",
    "            _, predicted_right = torch.max(outputs_right.data, 1)\n",
    "            total_train_right += labels.size(0)\n",
    "            for k in range(labels.size(0)):\n",
    "                if(labels_group_right[k]==predicted_right[k]):\n",
    "                    correct_train_right = correct_train_right+1\n",
    "\n",
    "\n",
    "        train_accuracy = 100 * (correct_train_left+correct_train_right) / (total_train_left+total_train_right)\n",
    "        train_losses.append((running_loss_right+running_loss_left) / (2*len(train_loader)))\n",
    "        train_acc.append(train_accuracy)\n",
    "        # left half\n",
    "        model_left.eval()\n",
    "        val_loss_left = 0.0\n",
    "        correct_val_left = 0\n",
    "        total_val_left = 0\n",
    "        count_left = 0\n",
    "        # right half\n",
    "        model_right.eval()\n",
    "        val_loss_right = 0.0\n",
    "        correct_val_right = 0\n",
    "        total_val_right = 0\n",
    "        count_right = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                # left half\n",
    "                labels_group_left = labels // 10\n",
    "                image_left = images.clone()\n",
    "                left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "                image_left[:, :, :, (image_left.shape[3] // 2):] = left_half\n",
    "                outputs_left = model_left(image_left)\n",
    "                loss_left = criterion_left(outputs_left, labels_group_left)\n",
    "                val_loss_left += loss_left.item()\n",
    "                _, predicted_left = torch.max(outputs_left.data, 1)\n",
    "                total_val_left += labels.size(0)\n",
    "                correct_val_left += (predicted_left == labels_group_left).sum().item()\n",
    "                count_left = count_left+1\n",
    "                # right half\n",
    "                labels_group_right = labels % 10\n",
    "                image_right = images.clone()\n",
    "                right_half = images[:, :, :, images.shape[3] // 2:]\n",
    "                image_right[:, :, :, :(image_right.shape[3] // 2)] = right_half\n",
    "                outputs_right = model_right(image_right)\n",
    "                loss_right = criterion_right(outputs_right, labels_group_right)\n",
    "                val_loss_right += loss_right.item()\n",
    "                _, predicted_right = torch.max(outputs_right.data, 1)\n",
    "                total_val_right += labels.size(0)\n",
    "                correct_val_right += (predicted_right == labels_group_right).sum().item()\n",
    "                count_right = count_right+1\n",
    "\n",
    "            val_accuracy = 100 * (correct_val_left+correct_val_right) / (total_val_left+total_val_right)\n",
    "            val_losses.append((val_loss_left+val_loss_right) / (2*len(val_loader)))\n",
    "            val_acc.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    return train_losses, val_losses, train_acc, val_acc\n",
    "\n",
    "\n",
    "def test_model(model_left, model_right , test_loader, criterion_left,criterion_right):\n",
    "    # left half\n",
    "    model_left.eval()\n",
    "    test_loss_left = 0.0\n",
    "    correct_test_left = 0\n",
    "    total_test_left = 0\n",
    "    count_left = 0\n",
    "    # right half\n",
    "    model_right.eval()\n",
    "    test_loss_right = 0.0\n",
    "    correct_test_right = 0\n",
    "    total_test_right = 0\n",
    "    count_right = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # left half\n",
    "            labels_group_left = labels // 10\n",
    "            image_left = images.clone()\n",
    "            left_half = images[:, :, :, :images.shape[3] // 2]\n",
    "            image_left[:, :, :, (image_left.shape[3] // 2):] = left_half\n",
    "            outputs_left = model_left(image_left)\n",
    "            loss_left = criterion_left(outputs_left, labels_group_left)\n",
    "            test_loss_left += loss_left.item()\n",
    "            _, predicted_left = torch.max(outputs_left.data, 1)\n",
    "            total_test_left += labels.size(0)\n",
    "            correct_test_left += (predicted_left == labels_group_left).sum().item()\n",
    "            count_left = count_left+1\n",
    "            # right half\n",
    "            labels_group_right = labels % 10\n",
    "            image_right = images.clone()\n",
    "            right_half = images[:, :, :, images.shape[3] // 2:]\n",
    "            image_right[:, :, :, :(image_right.shape[3] // 2)] = right_half\n",
    "            outputs_right = model_right(image_right)\n",
    "            loss_right = criterion_right(outputs_right, labels_group_right)\n",
    "            test_loss_right += loss_right.item()\n",
    "            _, predicted_right = torch.max(outputs_right.data, 1)\n",
    "            total_test_right += labels.size(0)\n",
    "            correct_test_right += (predicted_right == labels_group_right).sum().item()\n",
    "            count_right = count_right+1\n",
    "        test_accuracy = 100 * (correct_test_left+correct_test_right) / (total_test_left+total_test_right)\n",
    "        average_test_loss = ((test_loss_left+test_loss_right) / (2*len(test_loader)))\n",
    "\n",
    "    print(f'Test Loss: {average_test_loss:.4f}, Test Acc: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.6381, Train Acc: 79.06%, Val Loss: 0.2061, Val Acc: 93.80%\n",
      "Epoch 2/5, Train Loss: 0.1895, Train Acc: 94.26%, Val Loss: 0.1347, Val Acc: 95.72%\n",
      "Epoch 3/5, Train Loss: 0.1339, Train Acc: 95.98%, Val Loss: 0.1048, Val Acc: 96.67%\n",
      "Epoch 4/5, Train Loss: 0.1039, Train Acc: 96.71%, Val Loss: 0.0937, Val Acc: 97.03%\n",
      "Epoch 5/5, Train Loss: 0.0850, Train Acc: 97.32%, Val Loss: 0.0830, Val Acc: 97.51%\n",
      "Test Loss: 0.0959, Test Acc: 97.14%\n"
     ]
    }
   ],
   "source": [
    "model_left = MultiMNIST_CNN(input_channels=1,num_classes=num_classes)\n",
    "model_right = MultiMNIST_CNN(input_channels=1,num_classes=num_classes)\n",
    "learning_rate = 0.001\n",
    "criterion_left = nn.CrossEntropyLoss()\n",
    "optimizer_left = optim.Adam(model_left.parameters(), lr=learning_rate)\n",
    "criterion_right = nn.CrossEntropyLoss()\n",
    "optimizer_right = optim.Adam(model_right.parameters(), lr=learning_rate)\n",
    "train_losses, val_losses, train_acc, val_acc = train_model(model_left=model_left,model_right=model_right,train_loader=train_loader, val_loader=val_loader, criterion_left=criterion_left, optimizer_left=optimizer_left,criterion_right=criterion_right,optimizer_right=optimizer_right,num_epochs=5)\n",
    "criterion_left = nn.CrossEntropyLoss()\n",
    "optimizer_left = optim.Adam(model_left.parameters(), lr=learning_rate)\n",
    "criterion_right = nn.CrossEntropyLoss()\n",
    "optimizer_right = optim.Adam(model_right.parameters(), lr=learning_rate)\n",
    "test_model(model_left=model_left,model_right=model_right,test_loader=test_loader,criterion_left=criterion_left,criterion_right=criterion_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN ON MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 16.8805, Test Acc: 4.98%\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = int(0.1 * len(trainset))\n",
    "test_size = len(trainset) - train_size - val_size\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(trainset, [train_size, val_size, test_size])\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "test_model(model_left=model_left,model_right=model_right,test_loader=test_loader,criterion_left=criterion_left,criterion_right=criterion_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the dataset, you can use np.load\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "data = np.load(\"permuted_mnist.npz\")\n",
    "permuted_x_train = data[\"train_images\"]\n",
    "y_train = data[\"train_labels\"]\n",
    "permuted_x_test = data[\"test_images\"]\n",
    "y_test = data[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(permuted_x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "permuted_x_test = torch.from_numpy(permuted_x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(x_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(permuted_x_test, y_test), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP on Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PermutedMNIST_MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_layers, hidden_neurons, dropout_rate=0.5):\n",
    "        super(PermutedMNIST_MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_neurons[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        for i in range(1, hidden_layers):\n",
    "            layers.append(nn.Linear(hidden_neurons[i-1], hidden_neurons[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(hidden_neurons[-1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.hidden(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_acc, val_acc = [] , []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_acc.append(train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_accuracy = 100 * correct_val / total_val\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_acc.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    return train_losses, val_losses, train_acc, val_acc \n",
    "\n",
    "\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        test_loss = (test_loss / len(test_loader))\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.3411, Train Acc: 90.57%, Val Loss: 0.1508, Val Acc: 95.48%\n",
      "Epoch 2/10, Train Loss: 0.1698, Train Acc: 95.30%, Val Loss: 0.1237, Val Acc: 96.53%\n",
      "Epoch 3/10, Train Loss: 0.1409, Train Acc: 96.19%, Val Loss: 0.1440, Val Acc: 96.48%\n",
      "Epoch 4/10, Train Loss: 0.1285, Train Acc: 96.57%, Val Loss: 0.1371, Val Acc: 96.73%\n",
      "Epoch 5/10, Train Loss: 0.1085, Train Acc: 97.21%, Val Loss: 0.1222, Val Acc: 97.30%\n",
      "Epoch 6/10, Train Loss: 0.1064, Train Acc: 97.24%, Val Loss: 0.1393, Val Acc: 96.82%\n",
      "Epoch 7/10, Train Loss: 0.0950, Train Acc: 97.57%, Val Loss: 0.1415, Val Acc: 97.12%\n",
      "Epoch 8/10, Train Loss: 0.0930, Train Acc: 97.70%, Val Loss: 0.1379, Val Acc: 97.22%\n",
      "Epoch 9/10, Train Loss: 0.0906, Train Acc: 97.74%, Val Loss: 0.1447, Val Acc: 97.32%\n",
      "Epoch 10/10, Train Loss: 0.0866, Train Acc: 97.88%, Val Loss: 0.1291, Val Acc: 97.40%\n",
      "Test Loss: 0.1481, Test Acc: 97.16%\n"
     ]
    }
   ],
   "source": [
    "model = PermutedMNIST_MLP(input_size=784,num_classes=10,hidden_layers=3,hidden_neurons=[256,256,256])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_losses, val_losses, train_acc, val_acc = train_model(model=model, train_loader=train_loader, val_loader=val_loader, criterion=criterion, optimizer=optimizer, num_epochs=10)\n",
    "test_model(model=model,test_loader=test_loader,criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN On Permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "data = np.load(\"permuted_mnist.npz\")\n",
    "permuted_x_train = data[\"train_images\"]\n",
    "y_train = data[\"train_labels\"]\n",
    "permuted_x_test = data[\"test_images\"]\n",
    "y_test = data[\"test_labels\"]\n",
    "x_train, x_val, y_train, y_val = train_test_split(permuted_x_train, y_train, test_size=0.1, random_state=42)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = torch.from_numpy(y_val).long()\n",
    "permuted_x_test = torch.from_numpy(permuted_x_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(x_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(permuted_x_test, y_test), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout_size=0.25, strides=2, kernel_size=3,pool_size = 2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=kernel_size,padding=int((kernel_size-1)/2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=pool_size,stride=strides)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size,padding=int((kernel_size-1)/2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=pool_size, stride=strides)\n",
    "        self.var1 = int((28-pool_size)/strides)+1\n",
    "        self.dim = int((self.var1-pool_size)/strides)+1\n",
    "        self.fc1 = nn.Linear(64 * self.dim * self.dim, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout_size)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool1(self.relu1(self.conv1(x)))\n",
    "        x = self.maxpool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1,64*self.dim*self.dim)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_acc, val_acc = [] , []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_acc.append(train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs.unsqueeze(1))\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_accuracy = 100 * correct_val / total_val\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_acc.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    return train_losses, val_losses, train_acc, val_acc \n",
    "\n",
    "\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs.unsqueeze(1))\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        test_loss = (test_loss / len(test_loader))\n",
    "\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.5713, Train Acc: 85.54%, Val Loss: 0.2277, Val Acc: 92.63%\n",
      "Epoch 2/5, Train Loss: 0.2320, Train Acc: 92.82%, Val Loss: 0.1914, Val Acc: 94.08%\n",
      "Epoch 3/5, Train Loss: 0.1858, Train Acc: 94.20%, Val Loss: 0.1637, Val Acc: 94.98%\n",
      "Epoch 4/5, Train Loss: 0.1575, Train Acc: 94.96%, Val Loss: 0.1865, Val Acc: 94.33%\n",
      "Epoch 5/5, Train Loss: 0.1429, Train Acc: 95.39%, Val Loss: 0.1510, Val Acc: 95.72%\n",
      "Test Loss: 0.1547, Test Acc: 95.37%\n"
     ]
    }
   ],
   "source": [
    "model = CNN(dropout_size=0.25, strides=2, kernel_size=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_losses, val_losses, train_acc, val_acc  = train_model(model=model, train_loader=train_loader, val_loader=val_loader, criterion=criterion, optimizer=optimizer, num_epochs=5)\n",
    "test_model(model=model,test_loader=test_loader,criterion=criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
