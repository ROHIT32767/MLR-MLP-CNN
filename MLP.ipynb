{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('WineQT.csv')\n",
    "# print(data)\n",
    "print(data.shape)\n",
    "# Describe the dataset\n",
    "description = data.describe()\n",
    "\n",
    "# Draw a histogram for each attribute\n",
    "data.hist(bins=20, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur dioxide,total sulfur dioxide,density,pH,sulphates,alcohol,quality,Id\n",
    "tuples = []\n",
    "for column in data.columns:\n",
    "    column_data = data[column]\n",
    "    mean = np.mean(column_data)\n",
    "    min = np.min(column_data)\n",
    "    max = np.max(column_data)\n",
    "    standard_deviation = np.std(column_data)\n",
    "    tuples.append((mean,standard_deviation,max,min))\n",
    "\n",
    "# df_metrics = pd.DataFrame(tuples,columns=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol','quality','Id'])\n",
    "df_metrics = pd.DataFrame(tuples, columns=['mean', 'standard_deviation', 'max', 'min'], index=data.columns)\n",
    "print(df_metrics)\n",
    "# Draw a pie chart for the 'quality' attribute\n",
    "quality_counts = data['quality'].value_counts()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(quality_counts, labels=quality_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Distribution of Quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Classification in Python from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptronClassification:\n",
    "    def __init__(self,input_layer_size,num_hidden_layers,hidden_layer_size,learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_layer_size = input_layer_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        '''\n",
    "        Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        '''\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self, z):\n",
    "        '''\n",
    "        Derivative of sigmoid function\n",
    "        Returns the derivative of the sigmoid function evaluated at z\n",
    "        '''\n",
    "        return np.exp(-z)/((1 + np.exp(-z))**2)\n",
    "    \n",
    "    def tanh(z):\n",
    "        return np.tanh(z)\n",
    "    \n",
    "    def relu(z):\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        A = [X]\n",
    "        Z = []\n",
    "        for layer in range(0,self.num_hidden_layers+1):\n",
    "            z = np.dot(A[layer],self.weights[layer])+self.biases[layer]\n",
    "            if self.activation == 'sigmoid':\n",
    "                a = self.sigmoid(z)\n",
    "            elif self.activation == 'tanh':\n",
    "                a = self.tanh(z)\n",
    "            elif self.activation == 'relu':\n",
    "                a = self.relu(z)\n",
    "\n",
    "\n",
    "    \n",
    "    def backward_propagation(self, X, y):\n",
    "        gradients = []\n",
    "        output = self.layer_outputs[-1]\n",
    "        error = y - output\n",
    "        delta = error * self.activation_derivative(output)\n",
    "        gradients.append(np.dot(self.layer_outputs[-2].T, delta))\n",
    "\n",
    "        for i in range(len(self.weights) - 2, -1, -1):\n",
    "            error = delta.dot(self.weights[i+1].T)\n",
    "            delta = error * self.activation_derivative(self.layer_outputs[i+1])\n",
    "            gradients.append(np.dot(self.layer_outputs[i].T, delta))\n",
    "\n",
    "        return gradients[::-1]\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
